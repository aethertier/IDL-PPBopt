{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac4ca16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn\tas nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\tas Data\n",
    "torch.manual_seed(8) # for reproduce\n",
    "\n",
    "import time\n",
    "import numpy as\tnp\n",
    "import gc\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "import pickle\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "# from tensorboardX\timport SummaryWriter\n",
    "torch.nn.Module.dump_patches = True\n",
    "import copy\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from rdkit import Chem\n",
    "# from rdkit.Chem import AllChem\n",
    "from rdkit.Chem\timport QED\n",
    "from rdkit.Chem\timport rdMolDescriptors, MolSurf\n",
    "from rdkit.Chem.Draw import\tSimilarityMaps\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem\timport AllChem\n",
    "from rdkit.Chem\timport rdDepictor\n",
    "from rdkit.Chem.Draw import\trdMolDraw2D\n",
    "from numpy.polynomial.polynomial import\tpolyfit\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "import matplotlib.pyplot as\tplt\n",
    "from matplotlib\timport gridspec\n",
    "import matplotlib.cm as\tcm\n",
    "import matplotlib\n",
    "#import seaborn as sns; sns.set_style(\"darkgrid\")\n",
    "from IPython.display import\tSVG, display\n",
    "#import\tsascorer\n",
    "import itertools\n",
    "from sklearn.metrics import\tr2_score\n",
    "import scipy\n",
    "\n",
    "import operator,pybel\n",
    "import os\n",
    "#import setting\n",
    "import warnings\n",
    "try:\n",
    "    from rdkit.Chem import AllChem\n",
    "    from rdkit import Chem\n",
    "    from rdkit.Chem import Draw\n",
    "    from rdkit.Chem.Draw import rdMolDraw2D\n",
    "    from rdkit.Chem import rdDepictor\n",
    "    import cairosvg\n",
    "except:\n",
    "    warnings.warn('Cannot import rdkit or cairosvg, so report is not supported')\n",
    "    Chem = None\n",
    "    setting.report_substructures = False\n",
    "\n",
    "from scipy import stats\n",
    "import operator\n",
    "from cairosvg import svg2png\n",
    "\n",
    "#then import my\town\tmodules\n",
    "from AttentiveFP import\tFingerprint, Fingerprint_viz, save_smiles_dicts, get_smiles_dicts, get_smiles_array, moltosvg_highlight\n",
    "from IDLPPBopt.sarpy import SARpy\n",
    "from IDLPPBopt.sarpy.SARpytools import *\n",
    "from IDLPPBopt.config import DEFAULT_MODEL_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9cf66f",
   "metadata": {},
   "source": [
    "# Related Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060195a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_for_viz(model, viz_list,batch_size):\n",
    "    model.eval()\n",
    "    test_MAE_list = []\n",
    "    test_MSE_list = []\n",
    "    mol_prediction_list = []\n",
    "    atom_feature_list = []\n",
    "    atom_weight_list = []\n",
    "    mol_feature_list = []\n",
    "    mol_feature_unbounded_list = []\n",
    "    batch_list = []\n",
    "    for i in range(0, len(viz_list), batch_size):\n",
    "        batch = viz_list[i:i+batch_size]\n",
    "        batch_list.append(batch)\n",
    "    for counter, batch in enumerate(batch_list):\n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(viz_list,get_smiles_dicts(batch))\n",
    "        atom_feature_viz, atom_attention_weight_viz, mol_feature_viz, mol_feature_unbounded_viz, mol_attention_weight_viz, mol_prediction = model(\n",
    "            torch.Tensor(x_atom), torch.Tensor(x_bonds),\n",
    "            torch.cuda.LongTensor(x_atom_index),\n",
    "            torch.cuda.LongTensor(x_bond_index),\n",
    "            torch.Tensor(x_mask))\n",
    "        #print(mol_attention_weight_viz[1].cpu().detach().numpy())\n",
    "        mol_prediction_list.append(mol_prediction.cpu().detach().squeeze().numpy())\n",
    "        atom_feature_list.append(np.stack([atom_feature_viz[L].cpu().detach().numpy() for L in range(radius+1)]))\n",
    "        atom_weight_list.append(np.stack([mol_attention_weight_viz[t].cpu().detach().numpy() for t in range(T)]))\n",
    "        mol_feature_list.append(np.stack([mol_feature_viz[t].cpu().detach().numpy() for t in range(T)]))\n",
    "        mol_feature_unbounded_list.append(np.stack([mol_feature_unbounded_viz[t].cpu().detach().numpy() for t in range(T)]))\n",
    "\n",
    "    mol_prediction_array = np.concatenate(mol_prediction_list,axis=0)\n",
    "    atom_feature_array = np.concatenate(atom_feature_list,axis=1)\n",
    "    #print(atom_weight_list)\n",
    "    atom_weight_array = np.concatenate(atom_weight_list,axis=1)\n",
    "    #print(atom_weight_array)\n",
    "    mol_feature_array = np.concatenate(mol_feature_list,axis=1)\n",
    "    mol_feature_unbounded_array = np.concatenate(mol_feature_unbounded_list,axis=1)\n",
    "#     print(mol_prediction_array.shape, atom_feature_array.shape, atom_weight_array.shape, mol_feature_array.shape)\n",
    "    return mol_prediction_array, atom_feature_array, atom_weight_array, mol_feature_array, mol_feature_unbounded_array\n",
    "\n",
    "def eval(model, dataset):\n",
    "    model.eval()\n",
    "#    eval_MAE_list = []\n",
    "#    eval_MSE_list = []\n",
    "#    y_val_list = []\n",
    "    y_pred_list = []\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)\n",
    "    for counter, eval_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[eval_batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "#         print(batch_df)\n",
    "#        y_val = batch_df[tasks[0]].values\n",
    "\n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        atoms_prediction, mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask))\n",
    "#        MAE = F.l1_loss(mol_prediction, torch.Tensor(y_val).view(-1,1), reduction='none')\n",
    "#        MSE = F.mse_loss(mol_prediction, torch.Tensor(y_val).view(-1,1), reduction='none')\n",
    "#         print(x_mask[:2],atoms_prediction.shape, mol_prediction,MSE)\n",
    "#        y_val_list.extend(y_val)\n",
    "        y_pred_list.extend(np.array(mol_prediction.data.squeeze().cpu().numpy()))\n",
    "\n",
    "#        eval_MAE_list.extend(MAE.data.squeeze().cpu().numpy())\n",
    "#        eval_MSE_list.extend(MSE.data.squeeze().cpu().numpy())\n",
    "#    r2 = r2_score(y_val_list,y_pred_list)\n",
    "#    pr2 = scipy.stats.pearsonr(y_val_list,y_pred_list)[0]\n",
    "    return y_pred_list\n",
    "\n",
    "def get_smi_aw(remained_df):\n",
    "    batch_size = len(remained_df.cano_smiles.values)\n",
    "    train_df_smiles = [Chem.MolToSmiles(Chem.MolFromSmiles(remained_df.cano_smiles.values[m]),isomericSmiles=True) for m in range(0,batch_size)]\n",
    "    mol_prediction_array, atom_feature_array, atom_weight_array, mol_feature_array, mol_feature_unbounded_array =  eval_for_viz(model_for_viz, train_df_smiles,batch_size)\n",
    "    x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(train_df_smiles,get_smiles_dicts(train_df_smiles))\n",
    "    smi_aw = {}\n",
    "    for i in range(batch_size):\n",
    "        smiles = train_df_smiles[i]\n",
    "        index_atom = smiles_to_rdkit_list[smiles]\n",
    "        weight_recoder = np.stack([atom_weight_array[:,i][0][m] for m in np.argsort(index_atom)]) #1 is wrong\n",
    "        atom_weight = [weight_recoder[m][0] for m in range(len(weight_recoder))]\n",
    "        smi_aw[smiles] = atom_weight  #atom_weight\n",
    "        #smi_ac[smiles] = np.sum(atom_weight)\n",
    "    return smi_aw\n",
    "\n",
    "\n",
    "def dataset(compounds):\n",
    "    dataset = []\n",
    "    for compound in compounds:\n",
    "        compound = readstring('smi',compound)\n",
    "        structure = Structure(compound)\n",
    "        dataset.append(structure)\n",
    "    return dataset\n",
    "\n",
    "def collectSubs(structures, grinder):\n",
    "    if not structures:\n",
    "        return []\n",
    "    substructures = []\n",
    "    for structure in structures:\n",
    "        substructures.extend(grinder.getFragments(structure))\n",
    "    #print(fragments(substructures)) #substructures generate by each iteration\n",
    "#    print('%s\\tsubstructures found...' % len(substructures))\n",
    "    return substructures + collectSubs(substructures, grinder)\n",
    "\n",
    "def fragments(substructures):\n",
    "    fragments = []\n",
    "    for i in range(len(substructures)):\n",
    "        fragments.append(substructures[i].smiles)\n",
    "    return fragments\n",
    "\n",
    "\n",
    "def drawmol(smiles, atom_weights,smarts=None):\n",
    "    min_value = np.min(atom_weights)\n",
    "    max_value = np.max(atom_weights)\n",
    "    mean_value = np.mean(atom_weights)\n",
    "    atom_weights = (atom_weights - min_value) / (max_value - min_value)\n",
    "#    atom_weights = (atom_weights -mean_value)*1e3\n",
    "    #print(atom_weights)\n",
    "    #print(bg.number_of_nodes())\n",
    "    \n",
    "    norm = matplotlib.colors.Normalize(vmin=0, vmax=1.28) #vmin=0.5 vmax=1.28\n",
    "    cmap = cm.get_cmap('Oranges')\n",
    "    plt_colors = cm.ScalarMappable(norm=norm,cmap=cmap)\n",
    "    atom_colors = {i: plt_colors.to_rgba(atom_weights[i]) for i in range(len(atom_weights))}\n",
    "#    print(atom_weights[2])\n",
    "    \n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    rdDepictor.Compute2DCoords(mol)\n",
    "    drawer = rdMolDraw2D.MolDraw2DSVG(700, 700)\n",
    "    drawer.SetFontSize(0.6)\n",
    "    op = drawer.drawOptions()\n",
    "    bond_list = []\n",
    "    bond_cols = {}\n",
    "    if smarts:\n",
    "        for smart in smarts:\n",
    "            patt = Chem.MolFromSmarts(smart)\n",
    "            atom_number = mol.GetSubstructMatch(patt)\n",
    "            for bond in patt.GetBonds():\n",
    "                aid1 = atom_number[bond.GetBeginAtomIdx()]\n",
    "                aid2 = atom_number[bond.GetEndAtomIdx()]\n",
    "                bond_list.append(mol.GetBondBetweenAtoms(aid1, aid2).GetIdx())\n",
    "            colors = [(0.8,0,0),(0.8,0,0),(0.8,0,0)]            \n",
    "            for bd in bond_list:\n",
    "                bond_cols[bd] = colors[i%4]\n",
    "    mol = rdMolDraw2D.PrepareMolForDrawing(mol)\n",
    "#    print(mol)\n",
    "    drawer.DrawMolecule(mol, highlightAtoms=range(len(atom_weights)),\n",
    "                             highlightBonds=bond_list,\n",
    "                             highlightAtomColors=atom_colors,\n",
    "                             highlightBondColors = bond_cols)\n",
    "    drawer.FinishDrawing()\n",
    "    svg = drawer.GetDrawingText()\n",
    "    svg = svg.replace('svg:', '')\n",
    "#     with open(str(smiles)+'.svg','w') as f:\n",
    "#         f.write(svg)\n",
    "    return svg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeeebd58",
   "metadata": {},
   "source": [
    "# Step 1. Prepare input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2dcd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = 'ppb'\n",
    "tasks = ['endpoint']\n",
    "\n",
    "raw_filename = \"input_compounds.csv\"\n",
    "feature_filename = raw_filename.replace('.csv','.pickle')\n",
    "\n",
    "filename = raw_filename.replace('.csv','')\n",
    "prefix_filename = raw_filename.split('/')[-1].replace('.csv','')\n",
    "smiles_tasks_df = pd.read_csv(raw_filename)\n",
    "smilesList = smiles_tasks_df.cano_smiles.values\n",
    "print(\"number of all smiles: \",len(smilesList))\n",
    "atom_num_dist = []\n",
    "remained_smiles = []\n",
    "canonical_smiles_list = []\n",
    "for smiles in smilesList:\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        atom_num_dist.append(len(mol.GetAtoms()))\n",
    "        remained_smiles.append(smiles)\n",
    "        canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "    except:\n",
    "        print(smiles)\n",
    "        pass\n",
    "print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "smiles_tasks_df = smiles_tasks_df[smiles_tasks_df[\"cano_smiles\"].isin(remained_smiles)]\n",
    "# print(smiles_tasks_df)\n",
    "smiles_tasks_df['cano_smiles'] =canonical_smiles_list\n",
    "assert canonical_smiles_list[0]==Chem.MolToSmiles(Chem.MolFromSmiles(smiles_tasks_df['cano_smiles'][0]), isomericSmiles=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24de2e49",
   "metadata": {},
   "source": [
    "# Step 2. Calculate molecule feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6ea307",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dicts = save_smiles_dicts(smilesList,filename)\n",
    "remained_df = smiles_tasks_df[smiles_tasks_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "uncovered_df = smiles_tasks_df.drop(remained_df.index)\n",
    "print(str(len(uncovered_df.cano_smiles))+' compounds cannot be featured')\n",
    "remained_df = remained_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1763ad3a",
   "metadata": {},
   "source": [
    "# Step 3. Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6d0c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "p_dropout= 0.1\n",
    "fingerprint_dim = 200\n",
    "\n",
    "weight_decay = 5 # also known as l2_regularization_lambda\n",
    "learning_rate = 2.5\n",
    "output_units_num = 1 # for regression model\n",
    "radius = 2\n",
    "T = 2\n",
    "\n",
    "x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array([canonical_smiles_list[0]],feature_dicts)\n",
    "num_atom_features = x_atom.shape[-1]\n",
    "num_bond_features = x_bonds.shape[-1]\n",
    "loss_function = nn.MSELoss()\n",
    "model = Fingerprint(radius, T, num_atom_features, num_bond_features,\n",
    "            fingerprint_dim, output_units_num, p_dropout)\n",
    "model.cuda()\n",
    "\n",
    "best_model = torch.load(DEFAULT_MODEL_PATH)\n",
    "\n",
    "best_model_dict = best_model.state_dict()\n",
    "best_model_wts = copy.deepcopy(best_model_dict)\n",
    "\n",
    "model.load_state_dict(best_model_wts)\n",
    "(best_model.align[0].weight == model.align[0].weight).all()\n",
    "\n",
    "model_for_viz = Fingerprint_viz(radius, T, num_atom_features, num_bond_features,\n",
    "            fingerprint_dim, output_units_num, p_dropout)\n",
    "model_for_viz.cuda()\n",
    "\n",
    "model_for_viz.load_state_dict(best_model_wts)\n",
    "(best_model.align[0].weight == model_for_viz.align[0].weight).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f480fccc",
   "metadata": {},
   "source": [
    "# Step 4. Predict values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc4fe3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "remain_pred_list = eval(model, remained_df)\n",
    "remained_df['Predicted_values'] = remain_pred_list\n",
    "remained_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3cf2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "remained_df.to_csv('temp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857b4e6a",
   "metadata": {},
   "source": [
    "# Step 5. Get atom attention weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1c788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notably: for more than 500 compounds, be cautious!\n",
    "smi_aw = get_smi_aw(remained_df)\n",
    "len(smi_aw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903ed4af",
   "metadata": {},
   "source": [
    "# Step 6. Identify Privileged Substructure for each molecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e391378",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key,value in smi_aw.items():\n",
    "    print(key)\n",
    "    grinder = Grinder(3,18)\n",
    "    fragment_list = fragments(collectSubs(dataset([key]),grinder))\n",
    "    psubs = []\n",
    "    for fragment in fragment_list:\n",
    "        patt = Chem.MolFromSmarts(fragment)\n",
    "        smiles = Chem.MolFromSmiles(key)\n",
    "        atom_numbers = smiles.GetSubstructMatches(patt)\n",
    "        for j in range(len(atom_numbers)):\n",
    "            fragment_atoms = [smi_aw[key][i] for i in atom_numbers[j]]\n",
    "            rest_atoms = [smi_aw[key][i] for i in range(0,len(smi_aw[key]),1) if i not in atom_numbers[j]]\n",
    "            if len(rest_atoms) < 3:\n",
    "                pass\n",
    "            else:\n",
    "                try:\n",
    "                    p_value = stats.mannwhitneyu(fragment_atoms,rest_atoms,alternative = 'greater')[1]\n",
    "                    if p_value < 0.05:\n",
    "                        psubs.append(fragment)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "    psubs_del = []\n",
    "    for i in range(len(psubs)-1):\n",
    "        for j in range(i+1,len(psubs)):\n",
    "            patt1 = Chem.MolFromSmarts(psubs[i])\n",
    "            patt2 = Chem.MolFromSmarts(psubs[j])\n",
    "            smi1 = Chem.MolFromSmiles(psubs[i])\n",
    "            smi2 = Chem.MolFromSmiles(psubs[j])\n",
    "            frag1 = smi2.HasSubstructMatch(patt1)\n",
    "            frag2 = smi1.HasSubstructMatch(patt2)\n",
    "            if frag1 == True:\n",
    "                if frag2 == False:\n",
    "                    psubs_del.append(psubs[i])\n",
    "            if frag1 == False:\n",
    "                if frag2 == True:\n",
    "                    psubs_del.append(psubs[j])\n",
    "    psub = [p for p in psubs if p not in psubs_del]\n",
    "    print(psub)\n",
    "    print('Predicted PPB fraction: '+str(remained_df[remained_df.cano_smiles == key].Predicted_values.values[0]))\n",
    "    print('Dectected Priviledged Substructures: ' +str(psub))\n",
    "    svg = drawmol(key,value,psub)\n",
    "    display(SVG(svg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507daf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminate_redundancy(frag_list,train_df_sort):\n",
    "    Fragments = []\n",
    "    for fragment in frag_list:\n",
    "        elim_red_frag = {}\n",
    "        elim_red_frag['Fragment'] = fragment\n",
    "        patt = Chem.MolFromSmarts(fragment)\n",
    "        Get_smiles_index = []\n",
    "        for key in train_df_sort.cano_smiles:\n",
    "            smiles = Chem.MolFromSmiles(key)\n",
    "            frag = smiles.HasSubstructMatch(patt)\n",
    "            if frag == True:\n",
    "                Get_smiles_index.append(train_df_sort[train_df_sort.cano_smiles == key].index.tolist()[0])\n",
    "            else:\n",
    "                pass\n",
    "        elim_red_frag['smiles_index'] = list(set(Get_smiles_index))\n",
    "        Fragments.append(elim_red_frag)\n",
    "#    print(Fragments)\n",
    "    Fragments_del_list = []\n",
    "    for i in range(len(Fragments)-1):\n",
    "        for j in range(i+1,len(Fragments)):\n",
    "            if Fragments[i]['smiles_index'] == Fragments[j]['smiles_index']:\n",
    "                patt1 = Chem.MolFromSmarts(Fragments[i]['Fragment'])\n",
    "                patt2 = Chem.MolFromSmarts(Fragments[j]['Fragment'])\n",
    "                smiles1 = Chem.MolFromSmiles(Fragments[i]['Fragment'])\n",
    "                smiles2 = Chem.MolFromSmiles(Fragments[j]['Fragment'])\n",
    "                frag1 = smiles2.HasSubstructMatch(patt1)\n",
    "                frag2 = smiles1.HasSubstructMatch(patt2)\n",
    "                if frag1 == True:\n",
    "                    if frag2 == False:\n",
    "                        Fragments_del_list.append(Fragments[i]['Fragment'])\n",
    "                if frag2 == True:\n",
    "                    if frag1 == False:\n",
    "                        Fragments_del_list.append(Fragments[j]['Fragment'])\n",
    "                if frag1 == False:\n",
    "                    if frag2 == False:\n",
    "                        pass\n",
    "    Final_Fragments_list = [f for f in frag_list if f not in Fragments_del_list]\n",
    "    return Final_Fragments_list\n",
    "\n",
    "def get_virtual_index(patt):\n",
    "    i = 0\n",
    "    virtual_index = []\n",
    "    for atom in patt.GetAtoms():\n",
    "        if atom.GetSymbol() != '*':\n",
    "            virtual_index.append(i)\n",
    "        i += 1\n",
    "    return virtual_index\n",
    "\n",
    "\n",
    "def get_R_virtual_index(patt):\n",
    "    i = 0\n",
    "    virtual_index = []\n",
    "    for atom in patt.GetAtoms():\n",
    "        if atom.GetSymbol() == '*':\n",
    "            virtual_index.append(i)\n",
    "        i += 1\n",
    "    return virtual_index\n",
    "\n",
    "def Find_second_level_substructures(SAs_list,train_df_sort):\n",
    "    result = []\n",
    "    for subs in SAs_list:\n",
    "        subs_smiles_list = []\n",
    "        non_toxicity_SAs = []\n",
    "        non_toxicity_SAs_values = {}\n",
    "        match_compounds_numb = 0\n",
    "        patt = Chem.MolFromSmarts(subs)\n",
    "        for key in train_df_sort.cano_smiles:\n",
    "            smiles = Chem.MolFromSmiles(key)\n",
    "            frag = smiles.HasSubstructMatch(patt)\n",
    "            if frag == True:\n",
    "                match_compounds_numb +=1\n",
    "                subs_smiles_list.append(key)\n",
    "        print(str(subs) + ' matches ' + str(match_compounds_numb)+' compounds')\n",
    "        grinder = Grinder(3,18)\n",
    "        subs_fragment = fragments(collectSubs(dataset(subs_smiles_list),grinder))\n",
    "        print('Totally find ' + str(len(subs_fragment)) + ' fragments')\n",
    "        for sub in subs_fragment:\n",
    "            sub_patt = Chem.MolFromSmarts(sub)\n",
    "            compounds_contain_activity = []\n",
    "            compounds_no_contain_activity = []\n",
    "            for smi in subs_smiles_list:\n",
    "                smile = Chem.MolFromSmiles(smi)\n",
    "                frags = smile.HasSubstructMatch(sub_patt)\n",
    "                if frags == True:\n",
    "                    activity = train_df_sort[train_df_sort.cano_smiles == smi].endpoint.values[0]\n",
    "                    compounds_contain_activity.append(activity)\n",
    "                else:\n",
    "                    inactivity = train_df_sort[train_df_sort.cano_smiles == smi].endpoint.values[0]\n",
    "                    compounds_no_contain_activity.append(inactivity)\n",
    "#           print('compounds contain '  + str(sub)+ ' is ' + str(len(compounds_contain_activity)))\n",
    "            if len(compounds_contain_activity) < 5:\n",
    "                pass\n",
    "            elif len(compounds_no_contain_activity) < 5:\n",
    "                pass\n",
    "            elif len(compounds_contain_activity)/len(compounds_no_contain_activity) > 4:\n",
    "                pass\n",
    "            elif len(compounds_no_contain_activity)/len(compounds_contain_activity) > 4:\n",
    "                pass\n",
    "            else:\n",
    "#               P_value = stats.mannwhitneyu(compounds_contain_activity,compounds_no_contain_activity,alternative = 'less')[1]  #'less' non_toxic\n",
    "                P_value = stats.mannwhitneyu(compounds_contain_activity,compounds_no_contain_activity)[1]\n",
    "                if P_value < 0.01:\n",
    "                    non_toxicity_SAs.append(sub)\n",
    "                    va = np.mean(compounds_contain_activity) - np.mean(compounds_no_contain_activity)\n",
    "                    non_toxicity_SAs_values[sub] = va\n",
    "#                    draw_violin(compounds_contain_activity,compounds_no_contain_activity)\n",
    "                    #print('None_toxicity_SAs: '    + str(sub) + ' number of compounds contain SAs & not : '+ str(len(compounds_contain_activity)) + ':' + str(len(compounds_no_contain_activity)))\n",
    "                else:\n",
    "                    pass\n",
    "        # Inside Molecule analysis\n",
    "        subs_smiles_list_df = pd.DataFrame(data = subs_smiles_list,columns = ['cano_smiles'])\n",
    "        non_toxicity_SAs1 = eliminate_redundancy(non_toxicity_SAs,subs_smiles_list_df)\n",
    "        print('For ' + str(subs)+' totally find '+ str(len(non_toxicity_SAs1))+ ' second-level substructures!')\n",
    "        for subss in non_toxicity_SAs1:\n",
    "            SAs_Non_SAs = {}\n",
    "            SAs_Non_SAs['SA'] = subs\n",
    "            SAs_Non_SAs['Non_SAs'] = subss\n",
    "            SAs_Non_SAs['score'] = non_toxicity_SAs_values[subss]\n",
    "            non_toxic_patt = Chem.MolFromSmarts(subss)\n",
    "            no_SA_R_index = get_R_virtual_index(non_toxic_patt)\n",
    "            stat1 = [[m] for m in range(len(no_SA_R_index))]\n",
    "            stat2 = []\n",
    "            RES = 0\n",
    "            CES = 0\n",
    "            NTS = 0\n",
    "            ZES = 0\n",
    "            for smiss in subs_smiles_list:\n",
    "                ssmile = Chem.MolFromSmiles(smiss)\n",
    "                ffrag = ssmile.HasSubstructMatch(non_toxic_patt)\n",
    "                if ffrag == True:\n",
    "                    atom_numbers_SAs = ssmile.GetSubstructMatches(patt)\n",
    "                    atom_numbers_non_SAs = ssmile.GetSubstructMatches(non_toxic_patt)\n",
    "                    SA_index = get_virtual_index(patt)\n",
    "                    no_SA_index = get_virtual_index(non_toxic_patt)\n",
    "                    for j in range(len(atom_numbers_non_SAs)):\n",
    "                        no_SA_distance_index = [atom_numbers_non_SAs[j][n] for n in no_SA_index]\n",
    "                        atom_index = [atom_numbers_non_SAs[j][m] for m in no_SA_R_index]\n",
    "                        for n in range(len(atom_index)):\n",
    "                            atom = ssmile.GetAtomWithIdx(atom_index[n]).GetSymbol()\n",
    "                            stat1[n].append(atom)\n",
    "                        for i in range(len(atom_numbers_SAs)):\n",
    "                            SA_distance_index = [atom_numbers_SAs[i][m] for m in SA_index]\n",
    "                            distance = Chem.GetDistanceMatrix(ssmile)\n",
    "                            subs_distance = np.array(distance[SA_distance_index,:][:,no_SA_distance_index])\n",
    "                            if subs_distance.min() == 0:\n",
    "                                RES += 1\n",
    "                            elif subs_distance.min() == 1:\n",
    "                                CES += 1 \n",
    "                            elif subs_distance.min() <= 3:\n",
    "                                ZES += 1\n",
    "                            else:\n",
    "                                NTS += 1\n",
    "            SAs_Non_SAs['RES'] = RES\n",
    "            SAs_Non_SAs['CES'] = CES\n",
    "            SAs_Non_SAs['NTS'] = NTS\n",
    "            SAs_Non_SAs['ZES'] = ZES\n",
    "            for x in range(len(stat1)):\n",
    "                stat3 = {}\n",
    "                for y in stat1[x]:\n",
    "                    stat3[y] = stat1[x].count(y)\n",
    "                stat2.append(stat3)\n",
    "            SAs_Non_SAs['R_group'] = stat2\n",
    "            result.append(SAs_Non_SAs)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b3a716",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'ppb_3922'\n",
    "df = pd.read_csv(target+'.csv')\n",
    "molset = [Chem.MolFromSmiles(smi) for smi in df.cano_smiles]\n",
    "train_df = df[df.set_split == 'train'].drop('set_split',axis=1).reset_index(drop= True)\n",
    "smi_list = [smi for smi in train_df.cano_smiles]\n",
    "train_df_sort = train_df.sort_values(by = 'endpoint',ascending = False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797632b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SA = ['CN1CC(*)C1']\n",
    "r = Find_second_level_substructures(SA,train_df_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632d4f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Results.smi','w') as f:\n",
    "    f.write('SA_Fragment\\tNAS\\tScore\\tRES\\tCES\\tZES\\tNTS\\n')\n",
    "    for\ti in range(len(r)):\n",
    "        f.write(str(r[i]['SA']) + '\\t' + \\\n",
    "                str(r[i]['Non_SAs']) + '\\t' + \\\n",
    "                str(r[i]['score']) + '\\t' + \\\n",
    "                str(r[i]['RES']) + '\\t' + \\\n",
    "                str(r[i]['CES']) + '\\t' + \\\n",
    "                str(r[i]['ZES']) + '\\t' + \\\n",
    "                str(r[i]['NTS']) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269eaa30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
